dagTimeout: 1200s
jobs:
  - sparkJob:
      jarFileUris:
        - gs://aleix-demos-bucket/jars/GcpPlayground-assembly-0.1.0-SNAPSHOT.jar
      mainClass: com.demos.quickstart.DataprocHelloWorld
      args:
        - "--env=dev"
        - "--executionMode=GCP"
      properties:
        spark.driver.cores: "2"
        spark.driver.memory: "2G"
        spark.executor.instances: "2"
        spark.executor.memory: "2G"
        spark.executor.cores: "2"
        spark.dynamicAllocation.enabled: "false"
        # properties to enable and save spark history logs
        spark.eventLog.enabled: "true"
        spark.eventLog.dir: "gs://spark-history-bucket/dataproc-hello-world/spark-job-history"
        spark.hadoop.yarn.nodemanager.remote-app-log-dir: "gs://spark-history-bucket/dataproc-hello-world/yarn-logs"
        spark.history.fs.logDirectory: "gs://spark-history-bucket/dataproc-hello-world/spark-job-history"
        spark.history.fs.gs.outputstream.type: "FLUSHABLE_COMPOSITE"
        spark.history.fs.gs.outputstream.sync.min.interval.ms: "5000ms"
    stepId: compute
placement:
  managedCluster:
    clusterName: @@CLUSTER_NAME
    config:
      endpointConfig:
        enableHttpPortAccess: true  # --enable-component-gateway
      configBucket: dataproc-stg-bucket
      tempBucket: dataproc-tmp-bucket
      softwareConfig:
        imageVersion: 2.2.2-debian12
      masterConfig:
        numInstances: 1
        machineTypeUri: 'e2-standard-2'
        diskConfig:
          bootDiskSizeGb: 100
      workerConfig:
        numInstances: 2
        machineTypeUri: 'e2-standard-2'
        diskConfig:
          bootDiskSizeGb: 100