dagTimeout: 1200s
jobs:
  - sparkJob:
      jarFileUris:
        - gs://aleix-demos-bucket/jars/GcpPlayground-assembly-0.1.0-SNAPSHOT.jar
      mainClass: com.spark.demos.sparkexercises.etl.EtlApp
      args:
        - "--env=dev"
        - "--executionMode=GCP"
        - "--etl=@@ETL"
        - "--targetRepo=@@TARGET_REPO"
      properties:
        spark.driver.cores: "2"
        spark.driver.memory: "2G"
        spark.executor.instances: "2"
        spark.executor.memory: "2G"
        spark.executor.cores: "2"
        spark.dynamicAllocation.enabled: "false"
        # jvm logs timezone config
        spark.driver.extraJavaOptions: "-Duser.timezone=Europe/Sofia"
        spark.executor.extraJavaOptions: "-Duser.timezone=Europe/Sofia"
        # properties to enable and save spark history logs
        spark.eventLog.enabled: "true"
        spark.eventLog.dir: "gs://@@SPARK_HISTORY_PATH/spark-job-history"
        spark.hadoop.yarn.nodemanager.remote-app-log-dir: "gs://@@SPARK_HISTORY_PATH/yarn-logs"
        spark.history.fs.logDirectory: "gs://@@SPARK_HISTORY_PATH/spark-job-history"
        spark.history.fs.gs.outputstream.type: "FLUSHABLE_COMPOSITE"
        spark.history.fs.gs.outputstream.sync.min.interval.ms: "5000ms"
    stepId: compute
placement:
  managedCluster:
    clusterName: @@CLUSTER_NAME
    config:
      initializationActions:
        "executableFile": "gs://aleix-demos-bucket/init_actions/set_timezone.sh"
        "executionTimeout": "300s"
      endpointConfig:
        enableHttpPortAccess: true
      configBucket: dataproc-stg-bucket
      tempBucket: dataproc-tmp-bucket
      softwareConfig:
        imageVersion: 2.2.2-debian12
      masterConfig:
        numInstances: 1
        machineTypeUri: 'e2-standard-2'
        diskConfig:
          bootDiskSizeGb: 100
      workerConfig:
        numInstances: 2
        machineTypeUri: 'e2-standard-2'
        diskConfig:
          bootDiskSizeGb: 100