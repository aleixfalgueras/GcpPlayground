dagTimeout: 1200s
jobs:
  - sparkJob:
      args:
        - gs://NOT_USED
      jarFileUris:
        - gs://NOT_USED
      mainClass: NOT_USED
      properties:
        spark.driver.cores: "2"
        spark.driver.memory: "4G"
        spark.executor.instances: "2"
        spark.executor.memory: "4G"
        spark.executor.cores: "4"
        spark.dynamicAllocation.enabled: "false"
        # properties to enable and save spark history logs
        spark.eventLog.enabled: "true"
        spark.eventLog.dir: "gs://@@GCS_SPARK_HISTORY@@/spark-job-history"
        spark.hadoop.yarn.nodemanager.remote-app-log-dir: "gs://@@GCS_SPARK_HISTORY@@/yarn-logs"
        spark.history.fs.logDirectory: "gs://@@GCS_SPARK_HISTORY@@/spark-job-history"
        spark.history.fs.gs.outputstream.type: "FLUSHABLE_COMPOSITE"
        spark.history.fs.gs.outputstream.sync.min.interval.ms: "5000ms"
    stepId: compute
parameters:
  - fields:
      - jobs['compute'].sparkJob.mainClass
    name: MAIN
  - fields:
      - jobs['compute'].sparkJob.jarFileUris[0]
    name: JAR
  - fields:
      - jobs['compute'].sparkJob.args[0]
    name: ARGS
placement:
  managedCluster:
    clusterName: @@DATAPROC_CLUSTER_NAME@@
    config:
      configBucket: @@GCS_PWCCLAKE_ES_DATAPROC_STAGING@@
      encryptionConfig:
        gcePdKmsKeyName: @@DATAPROC_KMS@@
      endpointConfig:
        enableHttpPortAccess: true
      gceClusterConfig:
        internalIpOnly: true
        metadata:
          stackdriver-monitoring-enabled: 'true'
          block-project-ssh-keys: 'true'
          serial-port-enable: 'false'
        serviceAccount: @@SA_DATAPROC@@
        serviceAccountScopes:
          - https://www.googleapis.com/auth/bigquery
        shieldedInstanceConfig:
          enableIntegrityMonitoring: true
          enableSecureBoot: true
          enableVtpm: true
        subnetworkUri: @@DATAPROC_SUBNET@@
        tags:
          - dataprocAleix
      softwareConfig:
        imageVersion: 2.0.56-debian10
        properties:
          'dataproc:dataproc.monitoring.stackdriver.enable': 'true'
          'dataproc:dataproc.logging.stackdriver.job.driver.enable': 'true'
          'dataproc:dataproc.logging.stackdriver.job.yarn.container.enable': 'true'
      masterConfig:
        machineTypeUri: "n1-standard-4"
      workerConfig:
        machineTypeUri: "n1-standard-4"
        numInstances: "2"
      tempBucket: @@GCS_DATAPROC_TEMP_BUCKET@@