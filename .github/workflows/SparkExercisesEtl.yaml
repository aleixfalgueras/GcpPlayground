name: Run SparkExercisesEtl

on:
  workflow_dispatch:
    inputs:
      build:
        description: 'Build before run workflow'
        required: true
        type: boolean
        default: false
      etl:
        description: 'ETL to execute'
        required: true
        type: choice
        options:
          - products
          - sellers
          - sales
          - all
        default: sellers
      targetRepo:
        description: 'Target repo'
        required: true
        type: choice
        options:
          - BQ
          - AVRO
          - PARQUET
        default: BQ
      cluster_type:
        description: 'Select cluster type'
        required: true
        type: choice
        options:
          - ephemeral
          - persistent (spark-exercises-etl-persistent)
        default: ephemeral
      cluster_name:
        description: 'Cluster name (ignored if cluster_type is persistent)'
        required: true
        type: string
        default: spark-exercises-etl

permissions:
  contents: read

env:
  ephemeral: ./src/main/resources/dataproc/workflowtemplate/SparkExercisesEtl_wt.yaml
  ephemeral_id: spark-exercises-etl
  persistent: ./src/main/resources/dataproc/workflowtemplate/SparkExercisesEtl_persistent_wt.yaml
  persistent_id: spark-exercises-etl-persistent

jobs:
  call_build_workflow:
    if: inputs.build == true
    uses: ./.github/workflows/build.yaml
    with:
      deploy: true
    secrets: inherit

  prepare_params:
    runs-on: ubuntu-latest
    outputs:
      workflow_template_path: ${{ steps.set_workflow_template_params.outputs.workflow_template_path }}
      workflow_template_id: ${{ steps.set_workflow_template_params.outputs.workflow_template_id }}
      cluster_name: ${{ steps.set_workflow_template_params.outputs.cluster_name }}
    steps:
      - id: set_workflow_template_params
        name: Set workflow template params output values
        run: |
          if [ "${{ github.event.inputs.cluster_type }}" == "ephemeral" ]; then
            echo "workflow_template_path=${{ env.ephemeral }}" >> "$GITHUB_OUTPUT"
            echo "workflow_template_id=${{ env.ephemeral_id }}" >> "$GITHUB_OUTPUT"
            echo "cluster_name=${{ inputs.cluster_name }}" >> "$GITHUB_OUTPUT"
          else
            echo "workflow_template_path=${{ env.persistent }}" >> "$GITHUB_OUTPUT"
            echo "workflow_template_id=${{ env.persistent_id }}" >> "$GITHUB_OUTPUT"
            echo "cluster_name=spark-exercises-etl-persistent" >> "$GITHUB_OUTPUT"
          fi

  call_run_dataproc_with_wt_workflow:
    needs: [call_build_workflow, prepare_params]
    if: always()
    uses: ./.github/workflows/run_dataproc_with_wt.yaml
    with:
      region: us-central1
      workflow_template_path: ${{ needs.prepare_params.outputs.workflow_template_path }}
      workflow_template_id: ${{ needs.prepare_params.outputs.workflow_template_id }}
      cluster_name: ${{ needs.prepare_params.outputs.cluster_name }}
      spark_history_bucket: spark-history-bucket
      custom_sed: s/@@ETL/${{ inputs.etl }}/g; s/@@TARGET_REPO/${{ inputs.targetRepo }}/g;
    secrets: inherit
